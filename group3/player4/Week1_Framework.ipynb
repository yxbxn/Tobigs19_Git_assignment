{"cells":[{"cell_type":"markdown","metadata":{"id":"bzAkPcLiznkx"},"source":["# Week1_Library 과제"]},{"cell_type":"markdown","metadata":{"id":"Cz9yP6gLznk8"},"source":["### Q1. Library 와 Framework 의 차이 간단하게 서술하시오. (100자 내외)"]},{"cell_type":"markdown","metadata":{"id":"nPcnH62Lznk_"},"source":["프레임워크\n","-\t프레임워크가 정해준 규칙에 따라서 코드를 짜야함\n","- 원하는 기능 구현에 집중하여 개발할 수 있도록 일정한 형태와 필요한 기능을 갖추고 있는 골격, 뼈대를 의미\n","\n","라이브러리\n","-\t코드를 위한 도구, 내 마음대로 실행 가능, import 해서 쓰는 것\n","- 소프트웨어를 개발할 때 컴퓨터 프로그램이 사용하는 비휘발성 자원의 모임. 즉 특정 기능을 모와둔 코드, 함수들의 집합이며 코드 작성 시 활용 가능한 도구"]},{"cell_type":"markdown","metadata":{"id":"0qEk9WznznlB"},"source":["### Q2. 딥러닝과 머신러닝의 관계 및 특징, 차이 간단하게 서술하시오. (200자 내외)"]},{"cell_type":"markdown","metadata":{"id":"0iO7_A3xznlC"},"source":["딥러닝과 머신러닝 관계\n","- 딥러닝은 인공신경망 알고리즘을 이용한\n","머신러닝의 한 분야\n","\n","딥러닝과 머신러닝 차이\n","- 머신러닝의 라이브러리는는 전처리 + 모델 돌리기 전 과정을 위한 함수가 많고, 딥러닝 라이브러리는 전처리보다는 모델에 치중, 파라미터가 훨씬 다양"]},{"cell_type":"markdown","metadata":{"id":"cKDFwjiDznlD"},"source":["### Q3. 아래의 코드에 주석 달기."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ByHroEgxznlE"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ctC2zl-8znlG"},"outputs":[],"source":["# 파이토치 관련 라이브러리 임포트\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import torchvision\n","import torchvision.transforms as transfroms\n","\n","\n","# cuda 사용 가능하면 cuda 이용, 안되면 cpu 사용\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","torch.manual_seed(45)\n","if device == 'cuda':\n","    torch.cuda.manual_seed_all(45)\n","print(device + \" is available\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dqt7mYBIznlJ"},"outputs":[],"source":["# 하이퍼파라미터 설정\n","learning_rate = 0.001\n","batch_size = 100\n","num_classes = 10\n","epochs = 5"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"W9ZZIlHlznlL"},"outputs":[],"source":["#데이터 불러오고 텐서로 바꾸기\n","#학습 및 테스트 데이터셋\n","train_set = torchvision.datasets.MNIST(\n","    root = './data/MNIST',\n","    train = True,\n","    download = True,\n","    transform = transfroms.Compose([\n","        transfroms.ToTensor() \n","    ])\n",")\n","\n","test_set = torchvision.datasets.MNIST(\n","    root = './data/MNIST',\n","    train = False,\n","    download = True,\n","    transform = transfroms.Compose([\n","        transfroms.ToTensor()\n","    ])\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rERkJFqPznlN"},"outputs":[],"source":["# 데이터 로드\n","train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size)\n","test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size)\n","\n","\n","examples = enumerate(train_set)\n","batch_idx, (example_data, example_targets) = next(examples)\n","example_data.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DYsecVGoznlP"},"outputs":[],"source":["\n","class ConvNet(nn.Module):\n","  # 초기화\n","  def __init__(self): \n","        super(ConvNet, self).__init__() # 상속\n","        # 레이어들 \n","        self.conv1 = nn.Conv2d(1, 10, kernel_size=5) \n","        self.conv2 = nn.Conv2d(10, 20, kernel_size=5) \n","        self.drop2D = nn.Dropout2d(p=0.25, inplace=False) \n","        self.mp = nn.MaxPool2d(2)\n","        self.fc1 = nn.Linear(320,100) \n","        self.fc2 = nn.Linear(100,10) \n","\n","  # forward\n","  def forward(self, x):\n","        x = F.relu(self.mp(self.conv1(x))) # conv1 -> maxpool -> relu \n","        x = F.relu(self.mp(self.conv2(x))) # -> conv2 -> maxpool -> relu\n","        x = self.drop2D(x)  # -> dropout\n","        x = x.view(x.size(0), -1) # 차원 변경\n","        x = self.fc1(x) # fully connected\n","        x = self.fc2(x)\n","        return F.log_softmax(x) # softmax -> log"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8CZt_LbkznlQ"},"outputs":[],"source":["\n","model = ConvNet().to(device) # ConvNet 객체 생성 후 cuda/cpu에 올리기\n","criterion = nn.CrossEntropyLoss().to(device) # 손실함수 정의\n","optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate) # optimizer 올리기"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"w-plo9HBznlR"},"outputs":[],"source":["# epoch마다 \n","for epoch in range(epochs): \n","    avg_cost = 0\n","    for data, target in train_loader:\n","        # data, target 올리기\n","        data = data.to(device)\n","        target = target.to(device)\n","        # gradients를 0으로 초기화\n","        optimizer.zero_grad()\n","        # 예측\n","        hypothesis = model(data)\n","        # 손실값\n","        cost = criterion(hypothesis, target)\n","        # backward\n","        cost.backward()\n","        # backward 단계에서 수집된 변화도로 매개변수를 조정\n","        optimizer.step() \n","        avg_cost += cost / len(train_loader) \n","    print('[Epoch: {:>4}]  cost = {:>.9}'.format(epoch + 1, avg_cost))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KpricFJnznlS"},"outputs":[],"source":["# eval\n","# evaluation 과정에서 사용하지 않아야 하는 layer들을 알아서 off 시키도록 하는 함수\n","model.eval()\n","#evaluation/validation 과정에선 보통 model.eval()과 torch.no_grad()를 함께 사용\n","with torch.no_grad(): \n","  # 맞춤\n","    correct = 0\n","  # 전체\n","    total = 0\n","  # 정확도 계산\n","    for data, target in test_loader:\n","        data = data.to(device)\n","        target = target.to(device)\n","        out = model(data)\n","        preds = torch.max(out.data, 1)[1] \n","        total += len(target) \n","        correct += (preds==target).sum().item() \n","        \n","    print('Test Accuracy: ', 100.*correct/total, '%')\n","     "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o4BQmGP4znlT"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"optyjMKtznlU"},"source":["## 첫 정규세션 들으시느라 고생 많으셨습니다."]},{"cell_type":"markdown","metadata":{"id":"Un-OdF3dznlV"},"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"},"vscode":{"interpreter":{"hash":"c8758ede8fb5b1b22b6571a5c50167e14022fbbcb9edb3d484f2c2c206d32150"}},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}